% Modified based on Xiaoming Sun's template

\documentclass{article}
\usepackage{amsmath,amsfonts,amsthm,amssymb}
\usepackage{indentfirst}
\usepackage{setspace}
\usepackage{fancyhdr}
\usepackage{lastpage}
\usepackage{extramarks}
\usepackage{chngpage}
\usepackage{soul,color}
\usepackage{graphicx,float,wrapfig}
\usepackage{ifpdf}
%\usepackage{CJKspace}
\usepackage{verbatim}
%\usepackage{ctex}
\usepackage{algorithm}
\usepackage{algorithmicx}
\usepackage{algpseudocode}
\usepackage{url}

\usepackage{natbib}

\usepackage[colorlinks, citecolor=blue]{hyperref}


% In case you need to adjust margins:
% \topmargin=-0.45in      %
% \evensidemargin=0in     %
% \oddsidemargin=0in      %
% \textwidth=6.5in        %
% \textheight=9.0in       %
% \headsep=0.25in         %

% Setup the header and footer
% \pagestyle{fancy}                                                       %
% \chead{\Title}  %
% \rhead{\firstxmark}                                                     %
% \lfoot{\lastxmark}                                                      %
% \cfoot{}                                                                %
% \rfoot{Page\ \thepage\ of\ \protect\pageref{LastPage}}                          %
% \renewcommand\headrulewidth{0.4pt}                                      %
% \renewcommand\footrulewidth{0.4pt}                                      %

% 可以自定义一些命令
\newcommand{\Answer}{\ \\\textbf{Answer:} }
\newcommand{\Acknowledgement}[1]{\ \\{\bf Acknowledgement:} #1}
\newcommand{\Reference}[1]{\ \\{\bf Reference:} #1}

%\newcommand\numberthis{\addtocounter{equation}{1}\tag{\theequation}}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% 标题部分
\title{\textmd{\bf Artificial Intelligence Project Proposal}\\
Hierarchical Reinforcement Learning for Sparse Rewards
}
\date{}
\author{}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}
\begin{spacing}{1.1}
\maketitle %\thispagestyle{empty}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Begin edit from here


\section{Problem}

Sparse reward is a fundamental challenging problem for RL. Hierarchical exploration approaches learns to select subgoals and how to achieve subgoals, which seems helpful for reinforcement learning with sparse rewards. There are several papers show that hierarchical exploration allows more quickly to explore regions far away than basic $\epsilon$-greedy exploration.

Some problems are remained. For example, why hierarchical exploration performs better than $\epsilon$-greedy exploration? Is there any other exploration method performing better?

\section{Existing Works}

\cite{AI-16}
This paper proposed
\cite{AI-17}

\cite{AI-18}

Something may be not so related:

\cite{AI-15}

\cite{AI-13}

\section{Limitation}

\section{Goal}

We hope to achieve one or more goals below.

\begin{itemize}
\item Design a hierarchical exploration algorithm which performs good under specific environment.
\item Improve hierarchical exploration algorithm mentions in papers.
\item Explain why hierarchical exploration performs better than $\epsilon$-greedy exploration.
\item Design a learning algorithm in environments with sparse feedbacks, which performs better than hierarchical exploration.
\end{itemize}


\bibliographystyle{plain}
\bibliography{refx}

% End edit to here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\end{spacing}
\end{document}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
